{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220901_bgerr3.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import math, time, copy\n",
    "\n",
    "import utils, parameters, Unet_models\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "dir_name        = \"20220901_bgerr\" + str(parameters.background_err)\n",
    "print(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_npz = np.load('dataset/N' + str(parameters.sigNoise) + '_training_set.npz')\n",
    "x_train_obs = training_set_npz['x_train_obs']\n",
    "x_train = training_set_npz['x_train']\n",
    "mask_train = training_set_npz['mask_train']\n",
    "\n",
    "x_val_obs = training_set_npz['x_val_obs']\n",
    "x_val = training_set_npz['x_val']\n",
    "mask_val = training_set_npz['mask_val']\n",
    "\n",
    "stdTr = training_set_npz['std']\n",
    "meanTr = training_set_npz['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "training_dataset  = torch.utils.data.TensorDataset(torch.Tensor(x_train_obs), torch.Tensor(x_train), torch.Tensor(mask_train))\n",
    "val_dataset       = torch.utils.data.TensorDataset(torch.Tensor(x_val_obs),  torch.Tensor(x_val), torch.Tensor(mask_val)) \n",
    "\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(training_dataset, batch_size=batchsize, shuffle=True, num_workers=4, pin_memory=True),\n",
    "    'val': torch.utils.data.DataLoader(val_dataset, batch_size=batchsize, shuffle=True, num_workers=4, pin_memory=True),\n",
    "}\n",
    "\n",
    "dataset_sizes = {'train': len(training_dataset), 'val': len(val_dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_head = Unet_models.L96_UnetConvRec_head().to(device)\n",
    "optimizer_model_head     = optim.Adam(model_head.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/python/virtualenv/py3.6-gpu/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dyn loss(gt): 2.9160e-02\n",
      "train rec loss: 5.9481e+00 dyn loss: 6.3491e-01 dyn loss(bg): 6.7616e-01 loss_R: 3.3174e+00 loss_I: 6.3239e+00\n",
      "dyn loss(gt): 2.9154e-02\n",
      "val rec loss: 4.0901e+00 dyn loss: 1.9921e-01 dyn loss(bg): 2.4080e-01 loss_R: 2.3158e+00 loss_I: 4.3436e+00\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train rec loss: 3.0770e+00 dyn loss: 1.4074e-01 dyn loss(bg): 1.7565e-01 loss_R: 1.8913e+00 loss_I: 3.2464e+00\n",
      "val rec loss: 2.5075e+00 dyn loss: 1.0374e-01 dyn loss(bg): 1.3748e-01 loss_R: 1.5677e+00 loss_I: 2.6418e+00\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train rec loss: 2.2286e+00 dyn loss: 8.1511e-02 dyn loss(bg): 1.1475e-01 loss_R: 1.4243e+00 loss_I: 2.3435e+00\n",
      "val rec loss: 2.0037e+00 dyn loss: 6.6047e-02 dyn loss(bg): 1.0149e-01 loss_R: 1.2715e+00 loss_I: 2.1083e+00\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train rec loss: 1.8360e+00 dyn loss: 6.3551e-02 dyn loss(bg): 9.5733e-02 loss_R: 1.2077e+00 loss_I: 1.9258e+00\n",
      "val rec loss: 1.7084e+00 dyn loss: 5.5238e-02 dyn loss(bg): 9.1655e-02 loss_R: 1.0974e+00 loss_I: 1.7957e+00\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train rec loss: 1.5784e+00 dyn loss: 5.6744e-02 dyn loss(bg): 8.8355e-02 loss_R: 1.0623e+00 loss_I: 1.6521e+00\n",
      "val rec loss: 1.5050e+00 dyn loss: 5.9268e-02 dyn loss(bg): 8.3287e-02 loss_R: 1.0459e+00 loss_I: 1.5706e+00\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train rec loss: 1.4181e+00 dyn loss: 5.1142e-02 dyn loss(bg): 8.2372e-02 loss_R: 9.7142e-01 loss_I: 1.4819e+00\n",
      "val rec loss: 1.3590e+00 dyn loss: 4.9675e-02 dyn loss(bg): 8.5132e-02 loss_R: 9.2923e-01 loss_I: 1.4204e+00\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train rec loss: 1.2929e+00 dyn loss: 4.7088e-02 dyn loss(bg): 7.8343e-02 loss_R: 8.9735e-01 loss_I: 1.3494e+00\n",
      "val rec loss: 1.2573e+00 dyn loss: 4.4323e-02 dyn loss(bg): 7.6364e-02 loss_R: 8.6414e-01 loss_I: 1.3134e+00\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train rec loss: 1.1780e+00 dyn loss: 4.3785e-02 dyn loss(bg): 7.4884e-02 loss_R: 8.2770e-01 loss_I: 1.2280e+00\n",
      "val rec loss: 1.2024e+00 dyn loss: 3.8057e-02 dyn loss(bg): 7.2014e-02 loss_R: 8.1408e-01 loss_I: 1.2579e+00\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train rec loss: 1.1159e+00 dyn loss: 4.0947e-02 dyn loss(bg): 7.2039e-02 loss_R: 7.8956e-01 loss_I: 1.1625e+00\n",
      "val rec loss: 1.1330e+00 dyn loss: 4.2047e-02 dyn loss(bg): 6.5486e-02 loss_R: 8.0300e-01 loss_I: 1.1801e+00\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train rec loss: 1.0411e+00 dyn loss: 3.9129e-02 dyn loss(bg): 7.0065e-02 loss_R: 7.4494e-01 loss_I: 1.0834e+00\n",
      "val rec loss: 1.0643e+00 dyn loss: 3.9133e-02 dyn loss(bg): 6.6543e-02 loss_R: 7.4696e-01 loss_I: 1.1096e+00\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train rec loss: 9.9281e-01 dyn loss: 3.7297e-02 dyn loss(bg): 6.8166e-02 loss_R: 7.1621e-01 loss_I: 1.0323e+00\n",
      "val rec loss: 1.0294e+00 dyn loss: 3.8012e-02 dyn loss(bg): 6.8465e-02 loss_R: 7.3342e-01 loss_I: 1.0717e+00\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train rec loss: 9.4070e-01 dyn loss: 3.6017e-02 dyn loss(bg): 6.6878e-02 loss_R: 6.8377e-01 loss_I: 9.7740e-01\n",
      "val rec loss: 9.8361e-01 dyn loss: 3.7963e-02 dyn loss(bg): 6.0204e-02 loss_R: 7.0945e-01 loss_I: 1.0228e+00\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train rec loss: 9.1826e-01 dyn loss: 3.4577e-02 dyn loss(bg): 6.5304e-02 loss_R: 6.6964e-01 loss_I: 9.5377e-01\n",
      "val rec loss: 9.5091e-01 dyn loss: 3.4638e-02 dyn loss(bg): 6.4503e-02 loss_R: 6.7523e-01 loss_I: 9.9029e-01\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train rec loss: 8.5882e-01 dyn loss: 3.3601e-02 dyn loss(bg): 6.4263e-02 loss_R: 6.3378e-01 loss_I: 8.9097e-01\n",
      "val rec loss: 9.2256e-01 dyn loss: 3.1167e-02 dyn loss(bg): 6.5571e-02 loss_R: 6.6008e-01 loss_I: 9.6006e-01\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train rec loss: 8.4086e-01 dyn loss: 3.2848e-02 dyn loss(bg): 6.3481e-02 loss_R: 6.2429e-01 loss_I: 8.7180e-01\n",
      "val rec loss: 9.1201e-01 dyn loss: 2.9214e-02 dyn loss(bg): 6.4618e-02 loss_R: 6.5381e-01 loss_I: 9.4890e-01\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train rec loss: 8.1261e-01 dyn loss: 3.1851e-02 dyn loss(bg): 6.2492e-02 loss_R: 6.0643e-01 loss_I: 8.4207e-01\n",
      "val rec loss: 8.9455e-01 dyn loss: 2.9603e-02 dyn loss(bg): 6.1561e-02 loss_R: 6.3986e-01 loss_I: 9.3094e-01\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train rec loss: 7.7700e-01 dyn loss: 3.1336e-02 dyn loss(bg): 6.1886e-02 loss_R: 5.8422e-01 loss_I: 8.0454e-01\n",
      "val rec loss: 8.4076e-01 dyn loss: 3.3032e-02 dyn loss(bg): 6.3098e-02 loss_R: 6.1732e-01 loss_I: 8.7268e-01\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train rec loss: 7.6817e-01 dyn loss: 3.1005e-02 dyn loss(bg): 6.1539e-02 loss_R: 5.8034e-01 loss_I: 7.9500e-01\n",
      "val rec loss: 8.2493e-01 dyn loss: 3.1019e-02 dyn loss(bg): 6.1751e-02 loss_R: 6.0221e-01 loss_I: 8.5674e-01\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train rec loss: 7.4082e-01 dyn loss: 3.0214e-02 dyn loss(bg): 6.0686e-02 loss_R: 5.6326e-01 loss_I: 7.6618e-01\n",
      "val rec loss: 8.5406e-01 dyn loss: 2.8433e-02 dyn loss(bg): 6.7170e-02 loss_R: 6.1603e-01 loss_I: 8.8806e-01\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train rec loss: 7.2503e-01 dyn loss: 3.0093e-02 dyn loss(bg): 6.0641e-02 loss_R: 5.5454e-01 loss_I: 7.4939e-01\n",
      "val rec loss: 8.1842e-01 dyn loss: 2.9666e-02 dyn loss(bg): 5.4606e-02 loss_R: 6.0532e-01 loss_I: 8.4887e-01\n",
      "\n",
      "Training complete in 3m 5s\n",
      "Best val reconstruction loss: 8.184229e-01\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "\n",
    "best_model_head_wts = copy.deepcopy(model_head.state_dict())\n",
    "best_loss_rec   = 1e10\n",
    "\n",
    "train_loss_rec_list = []\n",
    "val_loss_rec_list = []\n",
    "train_loss_dyn_list = []\n",
    "val_loss_dyn_list = []\n",
    "train_loss_dynbg_list = []\n",
    "val_loss_dynbg_list = []\n",
    "train_loss_R_list = []\n",
    "val_loss_R_list = []\n",
    "train_loss_I_list = []\n",
    "val_loss_I_list = []\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model_head.train()\n",
    "        else:\n",
    "            model_head.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss_rec    = 0.0\n",
    "        running_loss_dyn    = 0.0\n",
    "        running_loss_dyn_bg = 0.0\n",
    "        running_loss_dyn_gt = 0.0\n",
    "        running_loss_R      = 0.0\n",
    "        running_loss_I      = 0.0\n",
    "        num_loss            = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, targets, mask, in dataloaders[phase]:\n",
    "            mask        = mask.to(device)\n",
    "            targets     = targets.to(device)\n",
    "            inputs      = inputs.to(device)\n",
    "            \n",
    "            optimizer_model_head.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True): \n",
    "                outputs    = model_head(inputs * mask)\n",
    "                \n",
    "                loss_rec    = torch.mean((outputs - targets)**2)\n",
    "                loss_dyn_bg = utils.dynamic_loss(outputs, 1, meanTr, stdTr, 3)\n",
    "                loss_dyn_gt = utils.dynamic_loss(targets, 1, meanTr, stdTr, 3)\n",
    "                loss_dyn    = utils.dynamic_loss(outputs, 1, meanTr, stdTr, 1)\n",
    "                loss_R      = torch.sum((outputs - targets)**2 * mask) / torch.sum(mask)\n",
    "                loss_I      = torch.sum((outputs - targets)**2 * (1 - mask)) / torch.sum(1 - mask)\n",
    "    \n",
    "                loss = loss_rec\n",
    "        \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer_model_head.step()\n",
    "\n",
    "            running_loss_rec         += loss_rec.item()    * inputs.size(0) * stdTr**2\n",
    "            running_loss_dyn         += loss_dyn.item()    * inputs.size(0) * stdTr**2\n",
    "            running_loss_dyn_bg      += loss_dyn_bg.item() * inputs.size(0) * stdTr**2\n",
    "            running_loss_dyn_gt      += loss_dyn_gt.item() * inputs.size(0) * stdTr**2\n",
    "            running_loss_R           += loss_R.item()      * inputs.size(0) * stdTr**2\n",
    "            running_loss_I           += loss_I.item()      * inputs.size(0) * stdTr**2\n",
    "            num_loss                 += inputs.size(0)\n",
    "\n",
    "        epoch_loss_rec       = running_loss_rec    / num_loss\n",
    "        epoch_loss_dyn       = running_loss_dyn    / num_loss\n",
    "        epoch_loss_dyn_bg    = running_loss_dyn_bg / num_loss\n",
    "        epoch_loss_dyn_gt    = running_loss_dyn_gt / num_loss\n",
    "        epoch_loss_R         = running_loss_R      / num_loss\n",
    "        epoch_loss_I         = running_loss_I      / num_loss\n",
    "\n",
    "        if epoch == 0:\n",
    "            print('dyn loss(gt): {:.4e}'.format(epoch_loss_dyn_gt))\n",
    "        print('{} rec loss: {:.4e} dyn loss: {:.4e} dyn loss(bg): {:.4e} loss_R: {:.4e} loss_I: {:.4e}'.format(\n",
    "            phase, epoch_loss_rec, epoch_loss_dyn, epoch_loss_dyn_bg, epoch_loss_R, epoch_loss_I))\n",
    "        \n",
    "        if phase == 'train':\n",
    "            train_loss_rec_list.append(epoch_loss_rec)\n",
    "            train_loss_dyn_list.append(epoch_loss_dyn)\n",
    "            train_loss_dynbg_list.append(epoch_loss_dyn_bg)\n",
    "            train_loss_R_list.append(epoch_loss_R)\n",
    "            train_loss_I_list.append(epoch_loss_I)\n",
    "        else:\n",
    "            val_loss_rec_list.append(epoch_loss_rec)\n",
    "            val_loss_dyn_list.append(epoch_loss_dyn)\n",
    "            val_loss_dynbg_list.append(epoch_loss_dyn_bg)\n",
    "            val_loss_R_list.append(epoch_loss_R)\n",
    "            val_loss_I_list.append(epoch_loss_I)\n",
    "\n",
    "        if phase == 'val' and epoch_loss_rec < best_loss_rec:\n",
    "            best_loss_rec = epoch_loss_rec\n",
    "            best_model_head_wts = copy.deepcopy(model_head.state_dict())\n",
    "\n",
    "    print()\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val reconstruction loss: {:4e}'.format(best_loss_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model at ckpts/20220901_bgerr3.5/pretrain_head_epoch20\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"ckpts/\" + dir_name):\n",
    "    os.makedirs(\"ckpts/\" + dir_name)\n",
    "\n",
    "save_dir_model_head = \"ckpts/\" + dir_name + \"/pretrain_head_epoch20\"\n",
    "print(\"saving model at \" + save_dir_model_head)\n",
    "torch.save(best_model_head_wts, save_dir_model_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving loss at train_loss/20220901_bgerr3.5/pretrain_head_epoch20\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"train_loss/\" + dir_name):\n",
    "    os.makedirs(\"train_loss/\" + dir_name)\n",
    "\n",
    "save_dir_loss_head  = \"train_loss/\" + dir_name + \"/pretrain_head_epoch20\"\n",
    "print(\"saving loss at \" + save_dir_loss_head)\n",
    "np.savez(save_dir_loss_head,\n",
    "         train_loss_rec   = train_loss_rec_list,   val_loss_rec   = val_loss_rec_list, \n",
    "         train_loss_dyn   = train_loss_dyn_list,   val_loss_dyn   = val_loss_dyn_list,\n",
    "         train_loss_dynbg = train_loss_dynbg_list, val_loss_dynbg = val_loss_dynbg_list,\n",
    "         train_loss_R     = train_loss_R_list,     val_loss_R     = val_loss_R_list, \n",
    "         train_loss_I     = train_loss_I_list,     val_loss_I     = val_loss_I_list,\n",
    "         time = time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
